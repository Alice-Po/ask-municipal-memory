/**
 * =============================================================================
 * API ROUTE: QDRANT UPLOADER - DOCUMENT INDEXING PIPELINE
 * =============================================================================
 *
 * ENDPOINT: POST /api/QdrantUploader
 *
 * DESCRIPTION:
 * Cette API route g√®re l'indexation des documents municipaux dans la base de
 * donn√©es vectorielle Qdrant. Elle impl√©mente un pipeline complet de traitement
 * des documents : d√©coupage en chunks, g√©n√©ration d'embeddings, et stockage
 * avec m√©tadonn√©es enrichies.
 *
 * PIPELINE D'INDEXATION:
 * 1. Validation des donn√©es d'entr√©e
 * 2. V√©rification/cr√©ation de la collection Qdrant
 * 3. D√©coupage des pages en chunks de texte
 * 4. G√©n√©ration d'embeddings pour chaque chunk
 * 5. Stockage avec m√©tadonn√©es compl√®tes
 *
 * UTILISATION P√âDAGOGIQUE:
 * Ce fichier illustre les concepts fondamentaux du RAG :
 * - Pr√©processing des documents
 * - Chunking intelligent
 * - G√©n√©ration d'embeddings
 * - Stockage vectoriel avec m√©tadonn√©es
 * - Gestion d'erreurs robuste
 *
 * TECHNOLOGIES UTILIS√âES:
 * - Qdrant Vector Database (stockage)
 * - Hugging Face Inference API (embeddings)
 * - Node.js crypto (g√©n√©ration d'IDs)
 *
 * PERFORMANCE:
 * - Chunking: ~1000 caract√®res par chunk
 * - Embeddings: 384 dimensions (all-MiniLM-L6-v2)
 * - M√©tadonn√©es: Compl√®tes pour tra√ßabilit√©
 *
 * =============================================================================
 */

export const prerender = false;

// =============================================================================
// IMPORTS ET CONFIGURATION
// =============================================================================

import { QdrantClient } from '@qdrant/js-client-rest';
import { InferenceClient } from '@huggingface/inference';
import { config } from 'dotenv';
import crypto from 'crypto';

// Chargement des variables d'environnement
config();

// =============================================================================
// CONSTANTES ET CONFIGURATION
// =============================================================================

/**
 * Configuration du chunking des documents
 */
const CHUNKING_CONFIG = {
  MAX_CHUNK_SIZE: 1000, // Taille maximale d'un chunk en caract√®res
  EMBEDDING_MODEL: 'sentence-transformers/all-MiniLM-L6-v2', // Mod√®le d'embeddings
  VECTOR_DISTANCE: 'Cosine', // M√©trique de similarit√© pour Qdrant
};

/**
 * Structure des m√©tadonn√©es stock√©es avec chaque chunk
 */
const METADATA_STRUCTURE = {
  text: 'string', // Contenu textuel du chunk
  filename: 'string', // Nom du fichier source
  filepath: 'string', // Chemin complet du fichier
  year: 'number', // Ann√©e du document
  page_number: 'number', // Num√©ro de page
  chunk_index: 'number', // Index du chunk dans la page
  total_chunks: 'number', // Nombre total de chunks dans la page
  timestamp: 'string', // Timestamp ISO de cr√©ation
  _timestamp: 'number', // Timestamp Unix pour indexation
};

// =============================================================================
// FONCTIONS UTILITAIRES
// =============================================================================

/**
 * D√©coupe un texte en chunks de taille optimale pour les embeddings
 *
 * Cette fonction impl√©mente un algorithme de chunking intelligent qui :
 * - Respecte les paragraphes naturels du texte
 * - √âvite de couper les mots au milieu
 * - Maintient une taille optimale pour les embeddings
 * - Pr√©serve la coh√©rence s√©mantique
 *
 * @param {string} text - Texte √† d√©couper
 * @param {number} maxLen - Taille maximale d'un chunk (d√©faut: 1000)
 * @returns {Array<string>} Tableau de chunks de texte
 *
 * @example
 * const chunks = chunkText("Paragraphe 1...\n\nParagraphe 2...", 1000);
 * // Retourne: ["Paragraphe 1...", "Paragraphe 2..."]
 */
function chunkText(text, maxLen = CHUNKING_CONFIG.MAX_CHUNK_SIZE) {
  const chunks = [];
  let current = '';

  // Division par paragraphes pour pr√©server la structure
  for (const paragraph of text.split(/\n+/)) {
    // Si l'ajout du paragraphe d√©passe la limite
    if ((current + paragraph).length > maxLen) {
      // Sauvegarde du chunk actuel s'il n'est pas vide
      if (current) chunks.push(current);
      // Commence un nouveau chunk avec le paragraphe actuel
      current = paragraph;
    } else {
      // Ajoute le paragraphe au chunk actuel
      current += (current ? '\n' : '') + paragraph;
    }
  }

  // Ajoute le dernier chunk s'il n'est pas vide
  if (current) chunks.push(current);

  return chunks;
}

/**
 * Valide les donn√©es d'entr√©e pour l'upload
 *
 * @param {Object} data - Donn√©es re√ßues de la requ√™te
 * @returns {Object} R√©sultat de validation avec statut et message
 */
function validateUploadData(data) {
  const { filename, filepath, year, pages } = data;

  // Validation des pages
  if (!pages || !Array.isArray(pages)) {
    return {
      valid: false,
      error: 'Format invalide: pages manquantes ou invalides',
    };
  }

  // Validation de la structure des pages
  for (const page of pages) {
    if (!page.text || typeof page.text !== 'string') {
      return {
        valid: false,
        error: 'Chaque page doit contenir un champ "text" valide',
      };
    }
    if (!page.page_number || typeof page.page_number !== 'number') {
      return {
        valid: false,
        error: 'Chaque page doit contenir un num√©ro de page valide',
      };
    }
  }

  return { valid: true };
}

/**
 * Cr√©e ou v√©rifie l'existence d'une collection Qdrant
 *
 * @param {QdrantClient} qdrant - Client Qdrant
 * @param {string} collectionName - Nom de la collection
 * @param {string} hfKey - Cl√© API Hugging Face
 * @param {string} sampleText - Texte d'exemple pour d√©terminer la taille des embeddings
 * @returns {Promise<void>}
 */
async function ensureCollectionExists(qdrant, collectionName, hfKey, sampleText) {
  try {
    // Tentative de r√©cup√©ration de la collection existante
    await qdrant.getCollection(collectionName);
    console.log(`[API] ‚úÖ Collection ${collectionName} existe d√©j√†`);
  } catch {
    // Collection inexistante, cr√©ation n√©cessaire
    console.log(`[API] üîß Cr√©ation de la collection ${collectionName}`);

    // G√©n√©ration d'un embedding de test pour d√©terminer la taille
    const hf = new InferenceClient(hfKey);
    const testEmbedding = await hf.featureExtraction({
      model: CHUNKING_CONFIG.EMBEDDING_MODEL,
      inputs: sampleText,
    });

    // Cr√©ation de la collection avec la configuration appropri√©e
    await qdrant.createCollection(collectionName, {
      vectors: {
        size: testEmbedding.length,
        distance: CHUNKING_CONFIG.VECTOR_DISTANCE,
      },
    });

    console.log(
      `[API] ‚úÖ Collection ${collectionName} cr√©√©e avec ${testEmbedding.length} dimensions`
    );
  }
}

/**
 * Traite une page et g√©n√®re ses embeddings
 *
 * @param {Object} page - Page √† traiter
 * @param {string} filename - Nom du fichier source
 * @param {string} filepath - Chemin du fichier
 * @param {number} year - Ann√©e du document
 * @param {InferenceClient} hf - Client Hugging Face
 * @param {QdrantClient} qdrant - Client Qdrant
 * @param {string} collectionName - Nom de la collection
 * @returns {Promise<number>} Nombre de chunks trait√©s
 */
async function processPage(page, filename, filepath, year, hf, qdrant, collectionName) {
  // D√©coupage de la page en chunks
  const chunks = chunkText(page.text, CHUNKING_CONFIG.MAX_CHUNK_SIZE);
  const pageChunks = chunks.length;

  console.log(`[API] üìÑ Traitement de la page ${page.page_number}: ${pageChunks} chunks`);

  // Traitement de chaque chunk
  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];

    // G√©n√©ration de l'embedding
    const embedding = await hf.featureExtraction({
      model: CHUNKING_CONFIG.EMBEDDING_MODEL,
      inputs: chunk,
    });

    // G√©n√©ration d'un ID unique pour le chunk
    const chunkId = crypto.randomUUID();

    // Pr√©paration des m√©tadonn√©es
    const payload = {
      text: chunk,
      filename: filename || 'unknown.txt',
      filepath: filepath || filename || 'unknown.txt',
      year: year || new Date().getFullYear(),
      page_number: page.page_number,
      chunk_index: i,
      total_chunks: pageChunks,
      timestamp: new Date().toISOString(),
      _timestamp: Date.now(),
    };

    // Stockage dans Qdrant
    await qdrant.upsert(collectionName, {
      points: [
        {
          id: chunkId,
          vector: embedding,
          payload: payload,
        },
      ],
    });

    console.log(
      `[API] ‚úÖ Page ${page.page_number}, Chunk ${i + 1}/${pageChunks} stock√© (ID: ${chunkId.substring(0, 8)}...)`
    );
  }

  return pageChunks;
}

// =============================================================================
// FONCTION PRINCIPALE - POST /api/QdrantUploader
// =============================================================================

/**
 * G√®re l'upload et l'indexation de documents dans Qdrant
 *
 * Cette fonction impl√©mente le pipeline complet d'indexation :
 * 1. Validation des donn√©es d'entr√©e
 * 2. Configuration des clients (Qdrant, Hugging Face)
 * 3. V√©rification/cr√©ation de la collection
 * 4. Traitement de chaque page (chunking + embeddings)
 * 5. Stockage avec m√©tadonn√©es compl√®tes
 *
 * @async
 * @param {Object} params - Param√®tres de la requ√™te Astro
 * @param {Request} params.request - Objet Request de la requ√™te HTTP
 * @returns {Promise<Response>} R√©ponse JSON avec statistiques d'indexation
 *
 * @example
 * // Requ√™te client
 * const response = await fetch('/api/QdrantUploader', {
 *   method: 'POST',
 *   headers: { 'Content-Type': 'application/json' },
 *   body: JSON.stringify({
 *     filename: 'compte-rendu-2025.pdf',
 *     filepath: '/data/municipal/compte-rendu-2025.pdf',
 *     year: 2025,
 *     pages: [
 *       { page_number: 1, text: 'Contenu de la page 1...' },
 *       { page_number: 2, text: 'Contenu de la page 2...' }
 *     ]
 *   })
 * });
 *
 * // R√©ponse
 * {
 *   success: true,
 *   total_chunks: 15,
 *   pages_processed: 2
 * }
 */
export async function POST({ request }) {
  console.log("[API] üöÄ D√©but de l'upload vers Qdrant");

  try {
    // =====================================================================
    // √âTAPE 1: VALIDATION ET EXTRACTION DES DONN√âES
    // =====================================================================

    console.log("[API] üìù Validation des donn√©es d'entr√©e...");
    const { filename, filepath, year, pages } = await request.json();

    // Validation des donn√©es
    const validation = validateUploadData({ filename, filepath, year, pages });
    if (!validation.valid) {
      console.error('[API] ‚ùå Validation √©chou√©e:', validation.error);
      return new Response(JSON.stringify({ error: validation.error }), { status: 400 });
    }

    console.log(`[API] ‚úÖ Validation r√©ussie: ${pages.length} pages √† traiter`);

    // =====================================================================
    // √âTAPE 2: CONFIGURATION DES CLIENTS
    // =====================================================================

    console.log('[API] üîß Configuration des clients...');
    const hfKey = process.env.HUGGINGFACE_API_KEY;
    const qdrantUrl = process.env.QDRANT_URL;
    const qdrantCollection = process.env.QDRANT_COLLECTION_NAME || 'municipal_council_minutes';
    const qdrantApiKey = process.env.QDRANT_API_KEY;

    // V√©rification des variables d'environnement
    if (!hfKey || !qdrantUrl) {
      throw new Error("Variables d'environnement manquantes: HUGGINGFACE_API_KEY ou QDRANT_URL");
    }

    // Initialisation des clients
    const qdrant = new QdrantClient({ url: qdrantUrl, apiKey: qdrantApiKey });
    const hf = new InferenceClient(hfKey);

    console.log('[API] ‚úÖ Clients configur√©s');

    // =====================================================================
    // √âTAPE 3: V√âRIFICATION/CR√âATION DE LA COLLECTION
    // =====================================================================

    console.log('[API] üóÑÔ∏è V√©rification de la collection Qdrant...');
    await ensureCollectionExists(qdrant, qdrantCollection, hfKey, pages[0].text);

    // =====================================================================
    // √âTAPE 4: TRAITEMENT DES PAGES
    // =====================================================================

    console.log('[API] üîÑ D√©but du traitement des pages...');
    let totalChunks = 0;

    // Traitement s√©quentiel de chaque page
    for (const page of pages) {
      const pageChunks = await processPage(
        page,
        filename,
        filepath,
        year,
        hf,
        qdrant,
        qdrantCollection
      );
      totalChunks += pageChunks;
    }

    // =====================================================================
    // √âTAPE 5: PR√âPARATION DE LA R√âPONSE
    // =====================================================================

    const responseData = {
      success: true,
      total_chunks: totalChunks,
      pages_processed: pages.length,
      filename: filename,
      year: year || new Date().getFullYear(),
      average_chunks_per_page: Math.round((totalChunks / pages.length) * 100) / 100,
    };

    console.log(
      `[API] ‚úÖ Upload termin√©: ${totalChunks} chunks index√©s pour ${pages.length} pages`
    );

    return new Response(JSON.stringify(responseData), { status: 200 });
  } catch (error) {
    // =====================================================================
    // GESTION D'ERREUR GLOBAL
    // =====================================================================

    console.error("[API] üí• Exception lors de l'upload:", error);
    console.error('[API] üìç Stack trace:', error.stack);

    return new Response(
      JSON.stringify({
        error: "Erreur lors de l'indexation du document",
        details: error.message,
      }),
      { status: 500 }
    );
  }
}

// =============================================================================
// GESTION DES M√âTHODES HTTP NON SUPPORT√âES
// =============================================================================

/**
 * G√®re les requ√™tes GET (non support√©es)
 *
 * @returns {Response} R√©ponse d'erreur 405
 */
export async function GET() {
  return new Response(JSON.stringify({ error: 'M√©thode GET non support√©e. Utilisez POST.' }), {
    status: 405,
    headers: { 'Content-Type': 'application/json' },
  });
}

/**
 * G√®re les requ√™tes PUT (non support√©es)
 *
 * @returns {Response} R√©ponse d'erreur 405
 */
export async function PUT() {
  return new Response(JSON.stringify({ error: 'M√©thode PUT non support√©e. Utilisez POST.' }), {
    status: 405,
    headers: { 'Content-Type': 'application/json' },
  });
}

/**
 * G√®re les requ√™tes DELETE (non support√©es)
 *
 * @returns {Response} R√©ponse d'erreur 405
 */
export async function DELETE() {
  return new Response(JSON.stringify({ error: 'M√©thode DELETE non support√©e. Utilisez POST.' }), {
    status: 405,
    headers: { 'Content-Type': 'application/json' },
  });
}
